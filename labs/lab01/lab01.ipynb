{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab01.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Examining the Therapeutic Touch\n",
    "\n",
    "Welcome to Lab 01 of DS 2: Intro to Data Science 2!\n",
    "\n",
    "After such an extensive introduction to programming for data science in DS 1, the first part of this Intro to Data Science series, we are finally moving into the section of the course where we can apply our new skills to answer real questions.  \n",
    "\n",
    "In this lab, we'll use testing techniques that were introduced in lecture to test the idea of the therapeutic touch, the idea that some practitioner can feel and massage your human energy field.\n",
    "\n",
    "This lab covers up to [Ch 11.3  of our Inferential Thinking textbook](https://inferentialthinking.com/chapters/11/3/Decisions_and_Uncertainty.html) and is designed to be a review of some DS 1 material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from matplotlib import patches\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Therapeutic Touch\n",
    "\n",
    "The Therapeutic Touch (TT) is the idea that everyone can feel the Human Energy Field (HEF) around individuals.  Those who practice TT have described different people's HEFs as \"warm as Jell-O\" and \"tactile as taffy.\" \n",
    "\n",
    "TT was a popular technique used throughout the 20th century that was toted as a great way to bring balance to a person's health. Certain practitioners claim they have the ability to feel the HEF and can massage it in order to promote health and relaxation in individuals.\n",
    "\n",
    "### Emily Rosa\n",
    "\n",
    "[Emily Rosa](https://en.wikipedia.org/wiki/Emily_Rosa) was a 4th grade student who was very familiar with the world of TT, thanks to her parents, who were both medical practitioners and skeptics of TT.\n",
    "\n",
    "For her 4th grade science fair project, Emily decided to test whether or not TT practitioners could truly interact with a person's HEF. She later went on to publish her work in TT, becoming the youngest person to have a research paper published in a peer reviewed medical journal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emily's Experiment\n",
    "\n",
    "Emily's experiment was clean, simple, and effective. Due to her parents' occupations in the medical field, she had wide access to people who claimed to be TT practitioners. \n",
    "\n",
    "Emily took 21 TT practitioners and used them for her science experiment. She would take a TT practitioner and ask them to extend their hands through a screen (which they can't see through). Emily would be on the other side and would flip a fair coin. Depending on how the coin landed, she would put out either her left hand or her right hand. The TT practitioner would then have to answer which hand Emily put out. If a pracitioner could truly interact with a person's HEF, it would be expected that they answered correctly.\n",
    "\n",
    "Overall, through 210 samples, the practitioner picked the correct hand 44% of the time. \n",
    "\n",
    "Emily's main goal here was to test whether or not the TT practicioners' guesses were random, like the flip of a coin. In most medical experiments, this is the norm. We want to test whether or not the treatment has an effect, *not* whether or not the treatment actually works. \n",
    "\n",
    "We will now begin to formulate this experiment in terms of the terminology we learned in this course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1**: Describe Emily’s model for how likely the TT practitioners are to choose the correct hand. What alternative model is her model meant to discredit? Discuss with students around you to come to a conclusion. Check in with a TA or LA if you are stuck.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2:** Remember that the practitioner got the correct answer 44% (0.44) of the time. According to Emily's model, on average, what proportion of times do we expect the practitioner to guess the correct hand? Make sure your answer is between 0 and 1. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_proportion_correct = ...\n",
    "expected_proportion_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1_2</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1_2 - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        0 <= expected_proportion_correct <= 1\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_2 0\n",
       "    Failed example:\n",
       "        0 <= expected_proportion_correct <= 1\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_2 0[0]>\", line 1, in <module>\n",
       "            0 <= expected_proportion_correct <= 1\n",
       "        TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "</pre><p><strong><pre style='display: inline;'>q1_2 - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        expected_proportion_correct == 0.5\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_2 1\n",
       "    Failed example:\n",
       "        expected_proportion_correct == 0.5\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre>"
      ],
      "text/plain": [
       "q1_2 results:\n",
       "    q1_2 - 1 result:\n",
       "        Trying:\n",
       "            0 <= expected_proportion_correct <= 1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_2 0\n",
       "        Failed example:\n",
       "            0 <= expected_proportion_correct <= 1\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_2 0[0]>\", line 1, in <module>\n",
       "                0 <= expected_proportion_correct <= 1\n",
       "            TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "\n",
       "    q1_2 - 2 result:\n",
       "        Trying:\n",
       "            expected_proportion_correct == 0.5\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_2 1\n",
       "        Failed example:\n",
       "            expected_proportion_correct == 0.5\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The goal now is to see if our deviation from this expected proportion of correct answers is due to something other than chance. \n",
    "\n",
    "**Question 3:** We usually use a statistic to help determine which model the evidence points towards. What is a statistic that we can use to compare outcomes under Emily’s model to what was observed? Assign `valid_stat` to an array of integer(s) representing test statistics that Emily can use: \n",
    "\n",
    "1. The difference between the expected percent correct and the actual percent correct\n",
    "2. The absolute difference between the expected percent correct and the actual percent correct\n",
    "3. The sum of the expected percent correct and the actual percent correct\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_stat = make_array(2)\n",
    "valid_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1_3 results: All test cases passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4:** Why is the statistic from Question 3 the best choice for comparing outcomes in Emily's experiment? How does it relate to the models you defined in question 1?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5:** Define the function `statistic` which takes in an expected proportion and an actual proportion, and returns the value of the statistic chosen in Question 3. Assume that the argument takes in proportions, but  return your answer as a percentage. \n",
    "\n",
    "*Hint:* Remember we are asking for a **percentage**, not a proportion. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(expected_prop, actual_prop):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1_5</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1_5 - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        int(round(statistic(.5,.5) + statistic(.4,.1),1)) == 30\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_5 0\n",
       "    Failed example:\n",
       "        int(round(statistic(.5,.5) + statistic(.4,.1),1)) == 30\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_5 0[0]>\", line 1, in <module>\n",
       "            int(round(statistic(.5,.5) + statistic(.4,.1),1)) == 30\n",
       "        TypeError: unsupported operand type(s) for +: 'NoneType' and 'NoneType'\n",
       "</pre><p><strong><pre style='display: inline;'>q1_5 - 2</pre> result:</strong></p><pre>    Trying:\n",
       "        int(statistic(.4,.1) - statistic(.1,.4)) == 0\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_5 1\n",
       "    Failed example:\n",
       "        int(statistic(.4,.1) - statistic(.1,.4)) == 0\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_5 1[0]>\", line 1, in <module>\n",
       "            int(statistic(.4,.1) - statistic(.1,.4)) == 0\n",
       "        TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'\n",
       "</pre>"
      ],
      "text/plain": [
       "q1_5 results:\n",
       "    q1_5 - 1 result:\n",
       "        Trying:\n",
       "            int(round(statistic(.5,.5) + statistic(.4,.1),1)) == 30\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_5 0\n",
       "        Failed example:\n",
       "            int(round(statistic(.5,.5) + statistic(.4,.1),1)) == 30\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_5 0[0]>\", line 1, in <module>\n",
       "                int(round(statistic(.5,.5) + statistic(.4,.1),1)) == 30\n",
       "            TypeError: unsupported operand type(s) for +: 'NoneType' and 'NoneType'\n",
       "\n",
       "    q1_5 - 2 result:\n",
       "        Trying:\n",
       "            int(statistic(.4,.1) - statistic(.1,.4)) == 0\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_5 1\n",
       "        Failed example:\n",
       "            int(statistic(.4,.1) - statistic(.1,.4)) == 0\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_5 1[0]>\", line 1, in <module>\n",
       "                int(statistic(.4,.1) - statistic(.1,.4)) == 0\n",
       "            TypeError: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6:** Use your newly defined function to calculate the observed statistic from Emily's experiment. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_statistic = ...\n",
    "observed_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1_6</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1_6 - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        int(round(observed_statistic,2)) == 6\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_6 0\n",
       "    Failed example:\n",
       "        int(round(observed_statistic,2)) == 6\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_6 0[0]>\", line 1, in <module>\n",
       "            int(round(observed_statistic,2)) == 6\n",
       "        TypeError: type ellipsis doesn't define __round__ method\n",
       "</pre>"
      ],
      "text/plain": [
       "q1_6 results:\n",
       "    q1_6 - 1 result:\n",
       "        Trying:\n",
       "            int(round(observed_statistic,2)) == 6\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_6 0\n",
       "        Failed example:\n",
       "            int(round(observed_statistic,2)) == 6\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_6 0[0]>\", line 1, in <module>\n",
       "                int(round(observed_statistic,2)) == 6\n",
       "            TypeError: type ellipsis doesn't define __round__ method"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this observed statistic consistent with what we might see under Emily’s model?**\n",
    "\n",
    "In order to answer this question, we must simulate the experiment as though Emily's model was correct, and calculate our statistic for every simulation.\n",
    "\n",
    "### `sample_proportions`\n",
    "\n",
    "`sample_proportions` can be used to randomly sample from multiple categories when you know the proportion of data points that are expected to fall in each category. `sample_proportions` takes two arguments: the sample size and an array that contains the distribution of categories in the population (should sum to 1).\n",
    "\n",
    "Consider flipping a fair coin, where the two outcomes (coin lands heads and coin lands tails) occur with an equal chance. We expect that half of all coin flips will land heads, and half of all coin flips will land tails.\n",
    "\n",
    "Run the following cell to see the simulation of 10 flips of a fair coin. Let the first item of `coin_proportions` be the proportion of heads and the second item of `coin_proportions` be the proportion of tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_proportions = make_array(0.5, 0.5) \n",
    "ten_flips = sample_proportions(10, coin_proportions)\n",
    "ten_flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_proportions` returns an array that is the same length as the proportion array that is passed through. It contains the proportion of each category that appears in the sample. \n",
    "\n",
    "In our example, the first item of `ten_flips` is the simulated proportion of heads and the second item of `ten_flips` is the simulated proportion of tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our simluation, 0.5 of flips were heads and 0.5 of flips were tails.\n"
     ]
    }
   ],
   "source": [
    "simluated_proportion_heads = ten_flips.item(0)\n",
    "simluated_proportion_tails = ten_flips.item(1)\n",
    "\n",
    "print(\"In our simluation, \" + str(simluated_proportion_heads) + \" of flips were heads and \" \\\n",
    "      + str(simluated_proportion_tails) + \" of flips were tails.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7:** To begin simulating, we should start by creating a representation of Emily's model to use for our simulation. This will be an array with two items in it. The first item should be the proportion of times, assuming that Emily’s model was correct, a TT practictioner picks the correct hand. The second item should be the proportion of times, under the same assumption, that the TT practitioner picks the incorrect hand. Assign `model_proportions` to this array. \n",
    "\n",
    "After this, we can simulate 210 hand choices, as Emily evaluated in real life, and find a single statistic to summarize this instance of the simulation. Use the `sample_proportions` function and assign the proportion of correct hand choices (out of 210) to `simulation_proportion_correct`. Lastly, use your statistic function to assign `one_statistic`  to the value of the statistic for this one simulation.\n",
    "\n",
    "*Hint:* `sample_proportions` usage can be found [here](http://data8.org/su19/python-reference.html).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_7\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_proportions = ...\n",
    "simulation_proportion_correct = ...\n",
    "one_statistic = ...\n",
    "one_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1_7</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1_7 - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        len(model_proportions) % 2 == 0\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_7 0\n",
       "    Failed example:\n",
       "        len(model_proportions) % 2 == 0\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_7 0[0]>\", line 1, in <module>\n",
       "            len(model_proportions) % 2 == 0\n",
       "        TypeError: object of type 'ellipsis' has no len()\n",
       "</pre><p><strong><pre style='display: inline;'>q1_7 - 2</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1_7 - 3</pre> result:</strong></p><pre>    Trying:\n",
       "        sum(model_proportions) == 1\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_7 2\n",
       "    Failed example:\n",
       "        sum(model_proportions) == 1\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_7 2[0]>\", line 1, in <module>\n",
       "            sum(model_proportions) == 1\n",
       "        TypeError: 'ellipsis' object is not iterable\n",
       "</pre><p><strong><pre style='display: inline;'>q1_7 - 4</pre> result:</strong></p><pre>    Trying:\n",
       "        type(simulation_proportion_correct) == float\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_7 3\n",
       "    Failed example:\n",
       "        type(simulation_proportion_correct) == float\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1_7 - 5</pre> result:</strong></p><pre>    Trying:\n",
       "        0 <= one_statistic <= 25\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1_7 4\n",
       "    Failed example:\n",
       "        0 <= one_statistic <= 25\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "            compileflags, 1), test.globs)\n",
       "          File \"<doctest q1_7 4[0]>\", line 1, in <module>\n",
       "            0 <= one_statistic <= 25\n",
       "        TypeError: '<=' not supported between instances of 'int' and 'ellipsis'\n",
       "</pre>"
      ],
      "text/plain": [
       "q1_7 results:\n",
       "    q1_7 - 1 result:\n",
       "        Trying:\n",
       "            len(model_proportions) % 2 == 0\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_7 0\n",
       "        Failed example:\n",
       "            len(model_proportions) % 2 == 0\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_7 0[0]>\", line 1, in <module>\n",
       "                len(model_proportions) % 2 == 0\n",
       "            TypeError: object of type 'ellipsis' has no len()\n",
       "\n",
       "    q1_7 - 2 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1_7 - 3 result:\n",
       "        Trying:\n",
       "            sum(model_proportions) == 1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_7 2\n",
       "        Failed example:\n",
       "            sum(model_proportions) == 1\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_7 2[0]>\", line 1, in <module>\n",
       "                sum(model_proportions) == 1\n",
       "            TypeError: 'ellipsis' object is not iterable\n",
       "\n",
       "    q1_7 - 4 result:\n",
       "        Trying:\n",
       "            type(simulation_proportion_correct) == float\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_7 3\n",
       "        Failed example:\n",
       "            type(simulation_proportion_correct) == float\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1_7 - 5 result:\n",
       "        Trying:\n",
       "            0 <= one_statistic <= 25\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1_7 4\n",
       "        Failed example:\n",
       "            0 <= one_statistic <= 25\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.7/doctest.py\", line 1329, in __run\n",
       "                compileflags, 1), test.globs)\n",
       "              File \"<doctest q1_7 4[0]>\", line 1, in <module>\n",
       "                0 <= one_statistic <= 25\n",
       "            TypeError: '<=' not supported between instances of 'int' and 'ellipsis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8:** Let's now see what the distribution of statistics is actually like under Emily's model. \n",
    "\n",
    "Define the function `simulation_and_statistic` to take in the `model_proportions` array and the expected proportion of times a TT practitioner would guess a hand correctly under Emily's model. The function should simulate Emily running through the experiment 210 times and return the statistic of this one simulation. \n",
    "\n",
    "*Hint:* This should follow the same pattern as the code you did in the previous problem.  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "def simulation_and_statistic(model_proportions, expected_proportion_correct):\n",
    "    '''Simulates 210 TT hand choices under Emily’s model. \n",
    "    Returns one statistic from the simulation.'''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using this function, assign `simulated_statistics` to an array of 1000 statistics that you calculated under the assumption that Emily's model was true.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to Ellipsis (<ipython-input-16-081896f2ee9a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-081896f2ee9a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for ... in ...:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to Ellipsis\n"
     ]
    }
   ],
   "source": [
    "num_repetitions = 1000\n",
    "\n",
    "simulated_statistics = ...\n",
    "\n",
    "for ... in ...:\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the distribution of the simulated statistics under Emily's model, and visually compare where the observed statistic lies relative to the simulated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Table().with_column('Simulated Statistics', simulated_statistics)\n",
    "t.hist()\n",
    "plt.scatter(observed_statistic, 0, color='red', s=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a visual argument as to whether we believe the observed statistic is consistent with Emily’s model. Here, since larger values of the test statistic suggest the alternative model (where the chance of guessing the correct hand is something other than 50%), we can formalize our analysis by finding what proportion of simulated statistics were as large or larger than our observed test statistic (the area at or to the right of the observed test statistic). If this area is small enough, we’ll declare that the observed data are inconsistent with our simulated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 9:** Calculate the proportion of simulated statistics greater than or equal to the observed statistic. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_9\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proportion_greater_or_equal = ...\n",
    "proportion_greater_or_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, we often compare the proportion we just calculated to 0.05. If the proportion of simulated statistics greater than or equal to the observed statistic is sufficiently small (less than or equal to 0.05), then this is evidence against Emily's model. Otherwise, we don’t have any reason to doubt Emily’s model. \n",
    "\n",
    "This should help you make your own conclusions about Emily Rosa's experiment. \n",
    "\n",
    "Therapeutic touch fell out of use after this experiment, which was eventually accepted into one of the premier medical journals. TT practitioners hit back and accused Emily and her family of tampering with the results, while some claimed that Emily's bad spiritual mood towards therapeutic touch made it difficult to read her HEF. Whatever it may be, Emily's experiment is a classic example about how anyone, with the right resources, can test anything they want!\n",
    "\n",
    "Think to yourself and be prepared to talk with your learning assistant and TA about the following questions as you get checked off: \n",
    "\n",
    "1. Is the data more consistent with Emily' model (practioners were randomly guessing)?\n",
    "2. What does this mean in terms of Emily's experiment? Do the TT practitioners' answers follow an even chance model or is there something else at play? \n",
    "\n",
    "Lastly, make sure to run all the tests (the next cell has a shortcut for that), save your work, and submit this notebook to Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your work ##\n",
    "\n",
    "Before you submit your work, \n",
    "* Make sure you **save the notebook** first, \n",
    "* Then go up to the `Kernel` menu and select `Restart & Clear Output` (make sure the notebook is saved first, because otherwise, you will lose all your work!). \n",
    "* Now, go to `Cell -> Run All`. Carefully look through your notebook and verify that all computations execute correctly. You should see **no errors**; if there are any errors, make sure to correct them before you submit the notebook.\n",
    "* Then, go to `File -> Download as -> Notebook` and download the notebook to your own computer. ([Please verify](https://ucsb-ds.github.io/ds1-f20/troubleshooting/#i-downloaded-the-notebook-file-but-it-saves-as-the-ipynbjson-extension-so-whenever-i-upload-it-to-gradescope-it-fails) that it got saved as an `.ipynb` file.)\n",
    "* Upload the notebook to [Gradescope](https://www.gradescope.com/).\n",
    "\n",
    "Congratulations! You are done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
